# FastAPI ML Inference Service

Simple ML inference API using FastAPI.

## Run locally
```bash
pip install -r requirements.txt
uvicorn app.main:app --reload


## Day 7 â€“ Model Versioning & Metrics

- Added model versioning (v1, v2)
- Latency & request tracking
- Production-ready inference endpoints
